# 快速入门指南

<cite>
**本文档引用的文件**   
- [README.md](file://README.md)
- [main.go](file://cmd/council/main.go)
- [QUICK_START.md](file://docs/templates/QUICK_START.md)
- [council-debate.md](file://docs/guide/council-debate.md)
- [custom-workflow.md](file://docs/guide/custom-workflow.md)
- [llm-providers.md](file://docs/guide/llm-providers.md)
- [model-selection-strategy.md](file://docs/guide/model-selection-strategy.md)
- [cost_estimation.md](file://docs/api/cost_estimation.md)
- [human_review.md](file://docs/api/human_review.md)
- [templates.md](file://docs/api/templates.md)
</cite>

## 目录
1. [简介](#简介)
2. [快速启动](#快速启动)
3. [内置理事会体验](#内置理事会体验)
4. [工作流使用指南](#工作流使用指南)
5. [自定义工作流](#自定义工作流)
6. [LLM提供商配置](#llm提供商配置)
7. [模型选型策略](#模型选型策略)
8. [API参考](#api参考)
9. [故障排查](#故障排查)

## 简介

理事会（The Council）是一个**可视化多智能体协作系统**和**个人私有思考库**，旨在通过AI驱动的辩论和优化流程，帮助用户做出更卓越的决策。

系统核心特性包括：
- **多智能体编排**：通过拖放式DAG编辑器实现AI智能体的可视化编排
- **智能节点**：支持投票、循环、事实核查和人工审核等高级决策节点
- **对抗性协作**：通过正反方辩论和首席裁决官的综合判决，锻造卓越决策
- **成本预估**：在执行前实时预估Token消耗和费用
- **三重记忆**：隔离区 → 工作记忆 → 长期知识的三级记忆体系

**Section sources**
- [README.md](file://README.md#L1-L352)

## 快速启动

### 前提条件

| 需求 | 版本 |
| :--- | :--- |
| Docker | ≥ 20.10 |
| Docker Compose | v2.x |
| Go | ≥ 1.21 |
| Node.js | ≥ 20 |

### 一键启动

```bash
# 克隆仓库
git clone https://github.com/hrygo/council.git
cd council

# 启动所有服务（Docker + 后端 + 前端）
make start
```

**访问应用：**
- 🌐 前端：http://localhost:5173
- 🔌 后端API：http://localhost:8080
- 📊 WebSocket：ws://localhost:8080/ws

### 手动启动

```bash
# 1. 启动基础设施（PostgreSQL + Redis）
make start-db

# 2. 启动后端
make start-backend

# 3. 启动前端
make start-frontend
```

### 停止服务

```bash
make stop
```

**Section sources**
- [README.md](file://README.md#L46-L90)

## 内置理事会体验

理事会是**开箱即用的AI治理委员会**，包含预配置的智能体和工作流，让您立即体验多智能体协作。

### 默认智能体

| 智能体 | 角色 | 模型 | 策略 |
| :--- | :--- | :--- | :--- |
| 🛡️ **价值辩护人** | 倡导战略价值 | Gemini 3 Pro | 创意性（temp: 0.9） |
| 🔍 **风险审计师** | 识别风险和漏洞 | DeepSeek | 逻辑性（temp: 0.6） |
| ⚖️ **首席裁决官** | 综合判决并交付裁决 | GLM-4.6 | 平衡性（temp: 0.2） |

### 可用工作流

1. **理事会辩论** - 单轮三方辩论并生成裁决
2. **理事会优化** - 带人工审核的迭代优化循环

### 立即体验

```bash
# 1. 启动服务器
make start

# 2. 打开浏览器
open http://localhost:5173

# 3. 从侧边栏选择"The Council"群组
# 4. 使用"Council Debate"工作流创建新会议
# 5. 上传文档并观察AI理事会的审议过程！
```

**Section sources**
- [README.md](file://README.md#L94-L123)

## 工作流使用指南

### 理事会辩论流程（单轮辩论）

#### 适用场景

- 快速评估方案的优劣
- 获取多角度分析意见
- 生成综合裁决报告

#### 流程图

```
📄 输入文档
     ↓
┌────┴────┐
↓         ↓
🛡️正方   🔍反方
↓         ↓
└────┬────┘
     ↓
⚖️ 裁决官
     ↓
📋 裁决报告
```

#### 使用步骤

1. **选择群组**：从侧边栏选择 "The Council"
2. **创建会议**：点击 "新建会议"，选择 "Council Debate" 模板
3. **输入文档**：将待审议文档粘贴到输入框或上传文件
4. **启动流程**：点击 "开始"，观察辩论过程
5. **阅读报告**：流程结束后查看裁决官的综合报告

**Section sources**
- [council-debate.md](file://docs/guide/council-debate.md#L25-L56)

### 理事会优化流程（迭代优化）

#### 适用场景

- 需要多轮迭代优化的文档
- 高质量输出（目标分数 ≥ 90）
- 需要人工介入决策的场景

#### 流程图

```
📄 输入文档
     ↓
🧠 Memory Retrieval (历史上下文)
     ↓
┌────┴────┐
↓         ↓
🛡️正方   🔍反方
↓         ↓
└────┬────┘
     ↓
⚖️ 裁决官 (输出评分)
     ↓
👤 Human Review
     ├─[继续] → 🔄 回到 Memory Retrieval
     ├─[应用] → ✅ 应用修改
     ├─[回滚] → ↩️ 恢复到上一版本
     └─[退出] → 📋 生成最终报告
```

#### 人工审核操作说明

当流程暂停在人工审核节点时，您会看到以下操作：

| 操作 | 效果 |
| :--- | :--- |
| **继续优化** | 进入下一轮辩论，直到分数达标或达到最大轮数 |
| **应用修改** | 将裁决官的建议应用到文档 |
| **回滚** | 恢复到本轮辩论前的文档版本 |
| **退出** | 立即结束流程，输出当前状态报告 |

**Section sources**
- [council-debate.md](file://docs/guide/council-debate.md#L68-L108)

## 自定义工作流

### 创建自定义智能体

#### 通过UI创建

1. 导航到 **智能体** (`/agents`)
2. 点击 **创建智能体** 按钮
3. 填写配置：
   - **名称**：智能体显示名称
   - **描述**：简短描述
   - **角色提示**：系统提示词（定义角色）
   - **提供商**：LLM服务商
   - **模型**：具体模型
   - **Temperature**：创造性 (0-1)
   - **Max Tokens**：最大输出长度

#### 角色提示编写技巧

一个好的角色提示应包含：
- **角色**：明确智能体的身份和专业领域
- **目标**：核心任务和目标
- **约束**：必须遵守的限制条件
- **工作流**：执行步骤和流程
- **输出格式**：必须严格按照指定格式输出

**Section sources**
- [custom-workflow.md](file://docs/guide/custom-workflow.md#L7-L52)

### 设计自定义工作流

#### 使用工作流画布

1. 导航到 **构建器** (`/builder`)
2. 从左侧 **节点调色板** 拖拽节点到画布
3. 连接节点定义执行流程
4. 点击节点配置属性

#### 节点类型说明

| 类型 | 图标 | 用途 | 配置项 |
| :--- | :--- | :--- | :--- |
| **开始** | ▶️ | 流程入口 | 无 |
| **结束** | ⏹️ | 流程出口 | summary_prompt |
| **智能体** | 🤖 | 调用AI智能体 | agent_id |
| **并行** | ⚡ | 并行分支 | 无 |
| **投票** | 🗳️ | 投票决策 | threshold, vote_type |
| **循环** | 🔄 | 循环逻辑 | max_rounds, exit_on_score |
| **事实核查** | ✅ | 事实核查 | verify_threshold |
| **人工审核** | 👤 | 人工审核 | timeout_minutes, allow_skip |
| **记忆检索** | 📚 | 历史检索 | max_results, time_range_days |

**Section sources**
- [custom-workflow.md](file://docs/guide/custom-workflow.md#L111-L133)

## LLM提供商配置

### 可用提供商列表

| 提供商 | 默认模型 | 特点 | 推荐场景 |
| :--- | :--- | :--- | :--- |
| **gemini** | gemini-2.0-flash | 超长上下文、多模态 | 文档分析、跨学科推理 |
| **deepseek** | deepseek-chat | 逻辑严密、代码能力强 | Bug修复、数学推导 |
| **siliconflow** | GLM-4.6 | 慢思考、智能体编排 | 复杂决策、多步推理 |
| **openai** | gpt-4o | 速度快、通用性强 | 日常对话、大批量处理 |
| **dashscope** | qwen-plus | 中文语义深、文化理解 | 公文写作、RAG问答 |
| **ollama** | llama3.2 | 本地部署、隐私保护 | 敏感数据、离线场景 |

### 环境变量配置

在项目根目录的 `.env` 文件中配置API Key：

```bash
# Google Gemini (价值辩护人)
GEMINI_API_KEY=your_gemini_api_key

# DeepSeek (风险审计师)
DEEPSEEK_API_KEY=your_deepseek_api_key

# SiliconFlow (首席裁决官)
SILICONFLOW_API_KEY=your_siliconflow_api_key

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# 阿里云DashScope
DASHSCOPE_API_KEY=your_dashscope_api_key

# 本地Ollama (无需API Key)
OLLAMA_BASE_URL=http://localhost:11434
```

**Section sources**
- [llm-providers.md](file://docs/guide/llm-providers.md#L7-L50)

## 模型选型策略

### 为什么需要模型异构？

单一模型家族的智能体群体存在**思维同质化盲区**：
- 相同的训练数据 → 相似的知识边界
- 相同的对齐方式 → 相似的价值倾向
- 相同的推理模式 → 相似的逻辑漏洞

**解决方案**：采用**"模型联邦" (Model Federation)** 策略。

### 角色阵营与模型配置

#### 正方 (价值辩护人)

| 配置项 | 值 | 理由 |
| :--- | :--- | :--- |
| **模型** | Google Gemini 3.0 Pro | 联想力强、跨学科能力突出 |
| **Temperature** | 0.9 | 鼓励发散思考、挖掘非显性价值 |
| **Top-P** | 0.95 | 保持较大采样空间 |

#### 反方 (风险审计师)

| 配置项 | 值 | 理由 |
| :--- | :--- | :--- |
| **模型** | DeepSeek-V3 | 逻辑严密、善于发现漏洞 |
| **Temperature** | 0.6 | 抑制幻觉、保持批判锐度 |
| **Top-P** | 0.85 | 适度收敛 |

#### 裁判 (首席裁决官)

| 配置项 | 值 | 理由 |
| :--- | :--- | :--- |
| **模型** | Zhipu GLM-4.6 | 中正平和、综合能力强 |
| **Temperature** | 0.2 | 保证判决稳定性和可复现性 |
| **Top-P** | 0.8 | 较小采样空间 |

**Section sources**
- [model-selection-strategy.md](file://docs/guide/model-selection-strategy.md#L7-L58)

## API参考

### 成本预估API

成本预估API用于在用户启动会议前，根据选定的模型配置和工作流复杂度预估本次会议的Token消耗和费用。

#### 预估工作流成本

```http
POST /api/v1/workflows/:id/estimate
```

**请求体：**
```json
{
  "proposal": "请分析这份商业计划书的可行性",
  "attachments": [
    {
      "filename": "business_plan.pdf",
      "size_bytes": 102400
    }
  ],
  "agent_overrides": {
    "agent-cfo": {
      "model": "gpt-4o-mini"
    }
  }
}
```

**响应：**
```json
{
  "workflow_id": "wf-001",
  "estimated_tokens": {
    "input": 12500,
    "output": 8000,
    "total": 20500
  },
  "estimated_cost": {
    "amount": 0.35,
    "currency": "USD"
  },
  "estimated_duration": {
    "seconds": 120,
    "formatted": "~2 分钟"
  }
}
```

**Section sources**
- [cost_estimation.md](file://docs/api/cost_estimation.md#L9-L140)

### 人工审核API

人工审核API用于支持工作流中的人类裁决节点。当工作流执行到人工审核节点时，后端暂停执行，等待用户审核并提交决定。

#### 提交人工审核

```http
POST /api/v1/sessions/:sessionId/review
```

**请求体：**
```json
{
  "review_id": "review-uuid",
  "action": "approve",
  "modified_content": null,
  "rejection_reason": null
}
```

**响应：**
```json
{
  "status": "accepted",
  "message": "裁决已接受，工作流继续执行",
  "next_node_id": "node-end"
}
```

**Section sources**
- [human_review.md](file://docs/api/human_review.md#L141-L166)

### 模板API

模板API用于管理可复用的工作流模板。用户可以将当前工作流保存为模板，也可以从模板创建新工作流。

#### 创建模板

```http
POST /api/v1/templates
```

**请求体：**
```json
{
  "name": "我的自定义模板",
  "description": "用于快速头脑风暴",
  "category": "custom",
  "graph": {
    "start_node_id": "node-start",
    "nodes": { }
  }
}
```

**响应：**
```json
{
  "id": "tpl-uuid-new",
  "name": "我的自定义模板",
  "description": "用于快速头脑风暴",
  "category": "custom",
  "is_system": false,
  "created_at": "2025-12-16T10:00:00Z",
  "updated_at": "2025-12-16T10:00:00Z"
}
```

**Section sources**
- [templates.md](file://docs/api/templates.md#L112-L134)

## 故障排查

### API Key无效

```
Error: 401 Unauthorized
```

检查：
1. `.env` 文件中的Key是否正确
2. Key是否有余额/配额
3. 服务是否在当前地区可用

### 模型不存在

```
Error: Model 'xxx' not found
```

检查：
1. 模型名称拼写是否正确
2. 该Key是否有该模型的访问权限
3. 模型是否已下线

### 连接超时

```
Error: context deadline exceeded
```

检查：
1. 网络是否畅通
2. 是否需要代理配置
3. 对于Ollama，检查服务是否启动

**Section sources**
- [llm-providers.md](file://docs/guide/llm-providers.md#L146-L177)