# 扩展开发

<cite>
**本文档中引用的文件**  
- [processor.go](file://internal/core/workflow/processor.go)
- [factory.go](file://internal/core/workflow/nodes/factory.go)
- [llm.go](file://internal/infrastructure/llm/llm.go)
- [router.go](file://internal/infrastructure/llm/router.go)
- [PropertyPanel.tsx](file://frontend/src/features/editor/components/PropertyPanel/PropertyPanel.tsx)
- [useWorkflowRunStore.ts](file://frontend/src/stores/useWorkflowRunStore.ts)
- [workflow.ts](file://frontend/src/types/workflow.ts)
- [App.tsx](file://frontend/src/App.tsx)
- [config.go](file://internal/pkg/config/config.go)
- [agent.go](file://internal/core/workflow/nodes/agent.go)
- [fact_check.go](file://internal/core/workflow/nodes/fact_check.go)
- [VoteNodeForm.tsx](file://frontend/src/features/editor/components/PropertyPanel/NodeForms/VoteNodeForm.tsx)
- [LoopNodeForm.tsx](file://frontend/src/features/editor/components/PropertyPanel/NodeForms/LoopNodeForm.tsx)
- [i18n/index.ts](file://frontend/src/i18n/index.ts)
</cite>

## 目录
1. [简介](#简介)
2. [工作流节点处理器扩展](#工作流节点处理器扩展)
3. [LLM提供商集成](#llm提供商集成)
4. [前端功能模块扩展](#前端功能模块扩展)
5. [扩展点设计原则](#扩展点设计原则)

## 简介
本指南详细说明了如何在系统中扩展功能，包括添加新的工作流节点处理器、集成新的LLM提供商以及扩展前端功能模块。文档涵盖了实现接口、注册工厂模式、定义前端组件和属性面板的具体步骤，并介绍了扩展点的设计原则。

## 工作流节点处理器扩展

系统通过`NodeProcessor`接口和工厂模式支持工作流节点的扩展。开发者可以通过实现处理器接口并将其注册到节点工厂来添加新的节点类型。

```mermaid
classDiagram
class NodeProcessor {
<<interface>>
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (output map[string]interface{}, err error)
}
class AgentProcessor {
+NodeID string
+AgentID string
+AgentRepo agent.Repository
+Registry *llm.Registry
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (map[string]interface{}, error)
}
class FactCheckProcessor {
+LLM llm.LLMProvider
+SearchClient search.SearchClient
+VerifyThreshold float64
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (map[string]interface{}, error)
}
class VoteProcessor {
+Threshold float64
+VoteType string
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (map[string]interface{}, error)
}
class LoopProcessor {
+MaxRounds int
+ExitOnScore int
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (map[string]interface{}, error)
}
class HumanReviewProcessor {
+TimeoutMinutes int
+AllowSkip bool
+Process(ctx context.Context, input map[string]interface{}, stream chan<- StreamEvent) (map[string]interface{}, error)
}
NodeProcessor <|-- AgentProcessor
NodeProcessor <|-- FactCheckProcessor
NodeProcessor <|-- VoteProcessor
NodeProcessor <|-- LoopProcessor
NodeProcessor <|-- HumanReviewProcessor
```

**图源**
- [processor.go](file://internal/core/workflow/processor.go#L7-L14)
- [agent.go](file://internal/core/workflow/nodes/agent.go#L16-L130)
- [fact_check.go](file://internal/core/workflow/nodes/fact_check.go#L14-L114)

**节源**
- [processor.go](file://internal/core/workflow/processor.go#L7-L14)
- [agent.go](file://internal/core/workflow/nodes/agent.go#L16-L130)
- [fact_check.go](file://internal/core/workflow/nodes/fact_check.go#L14-L114)

### 实现Processor接口
要添加新的工作流节点处理器，首先需要实现`NodeProcessor`接口。该接口定义了`Process`方法，接收上下文、输入数据和事件流通道，返回输出数据和可能的错误。

```mermaid
sequenceDiagram
participant Engine as Workflow Engine
participant Processor as NodeProcessor
participant Stream as Stream Channel
Engine->>Processor : Process(ctx, input, stream)
Processor->>Stream : 发送节点状态变更事件
alt 业务逻辑处理
Processor->>Processor : 执行节点特定逻辑
Processor->>Stream : 发送处理事件
end
Processor-->>Engine : 返回输出数据
```

**图源**
- [processor.go](file://internal/core/workflow/processor.go#L7-L14)
- [agent.go](file://internal/core/workflow/nodes/agent.go#L23-L124)

### 注册到工厂模式
新实现的处理器需要在`NewNodeFactory`函数中注册，通过节点类型进行分发。工厂函数根据节点类型创建相应的处理器实例。

```mermaid
flowchart TD
Start([开始]) --> CheckType["检查节点类型"]
CheckType --> TypeStart{"类型 == Start?"}
TypeStart --> |是| CreateStart["创建StartProcessor"]
TypeStart --> |否| TypeEnd{"类型 == End?"}
TypeEnd --> |是| CreateEnd["创建EndProcessor"]
TypeEnd --> |否| TypeAgent{"类型 == Agent?"}
TypeAgent --> |是| CreateAgent["创建AgentProcessor"]
TypeAgent --> |否| TypeVote{"类型 == Vote?"}
TypeVote --> |是| CreateVote["创建VoteProcessor"]
TypeVote --> |否| TypeLoop{"类型 == Loop?"}
TypeLoop --> |是| CreateLoop["创建LoopProcessor"]
TypeLoop --> |否| TypeFactCheck{"类型 == FactCheck?"}
TypeFactCheck --> |是| CreateFactCheck["创建FactCheckProcessor"]
TypeFactCheck --> |否| TypeHumanReview{"类型 == HumanReview?"}
TypeHumanReview --> |是| CreateHumanReview["创建HumanReviewProcessor"]
TypeHumanReview --> |否| Default["返回错误：不支持的节点类型"]
CreateStart --> Return
CreateEnd --> Return
CreateAgent --> Return
CreateVote --> Return
CreateLoop --> Return
CreateFactCheck --> Return
CreateHumanReview --> Return
Default --> Return
Return([返回处理器实例])
```

**图源**
- [factory.go](file://internal/core/workflow/nodes/factory.go#L20-L106)

### 定义前端组件和属性面板
前端需要为新节点类型定义相应的属性面板组件，允许用户配置节点参数。属性面板通过条件渲染支持不同节点类型的配置表单。

```mermaid
flowchart TD
PanelStart([属性面板渲染]) --> CheckNode{"节点存在?"}
CheckNode --> |否| ReturnNull
CheckNode --> |是| RenderForm["渲染表单"]
RenderForm --> NodeType{"节点类型"}
NodeType --> VoteNode["vote节点"]
NodeType --> LoopNode["loop节点"]
NodeType --> FactCheckNode["fact_check节点"]
NodeType --> HumanReviewNode["human_review节点"]
NodeType --> OtherNode["其他节点"]
VoteNode --> RenderVoteForm["渲染VoteNodeForm"]
LoopNode --> RenderLoopForm["渲染LoopNodeForm"]
FactCheckNode --> RenderFactCheckForm["渲染FactCheckNodeForm"]
HumanReviewNode --> RenderHumanReviewForm["渲染HumanReviewNodeForm"]
OtherNode --> RenderDefault["渲染默认配置"]
RenderVoteForm --> PanelEnd
RenderLoopForm --> PanelEnd
RenderFactCheckForm --> PanelEnd
RenderHumanReviewForm --> PanelEnd
RenderDefault --> PanelEnd
ReturnNull --> PanelEnd
PanelEnd([完成渲染])
```

**图源**
- [PropertyPanel.tsx](file://frontend/src/features/editor/components/PropertyPanel/PropertyPanel.tsx#L21-L42)

## LLM提供商集成

系统通过`LLMProvider`接口和注册中心模式支持LLM提供商的动态集成。新的LLM提供商可以通过实现接口并注册到路由系统来集成。

```mermaid
classDiagram
class LLMProvider {
<<interface>>
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
}
class Embedder {
<<interface>>
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class Registry {
-cfg *config.Config
-providers map[string]LLMProvider
-mu sync.RWMutex
+RegisterProvider(name string, provider LLMProvider)
+GetLLMProvider(providerName string) (LLMProvider, error)
+GetDefaultModel() string
+NewEmbedder(config EmbeddingConfig) (Embedder, error)
}
class OpenAIClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class GeminiClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class DeepSeekClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class OllamaClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class DashScopeClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
class SiliconFlowClient {
+Generate(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
+Stream(ctx context.Context, req *CompletionRequest) (<-chan string, <-chan error)
+Embed(ctx context.Context, model string, text string) ([]float32, error)
}
LLMProvider <|-- OpenAIClient
LLMProvider <|-- GeminiClient
LLMProvider <|-- DeepSeekClient
LLMProvider <|-- OllamaClient
LLMProvider <|-- DashScopeClient
LLMProvider <|-- SiliconFlowClient
Embedder <|-- OpenAIClient
Embedder <|-- GeminiClient
Embedder <|-- DeepSeekClient
Embedder <|-- OllamaClient
Embedder <|-- DashScopeClient
Embedder <|-- SiliconFlowClient
```

**图源**
- [llm.go](file://internal/infrastructure/llm/llm.go#L35-L47)
- [router.go](file://internal/infrastructure/llm/router.go#L13-L177)

**节源**
- [llm.go](file://internal/infrastructure/llm/llm.go#L35-L47)
- [router.go](file://internal/infrastructure/llm/router.go#L13-L177)

### 实现LLM接口
新的LLM提供商需要实现`LLMProvider`接口，提供`Generate`和`Stream`两个核心方法。`Generate`方法用于同步生成完整响应，`Stream`方法用于流式传输响应片段。

```mermaid
sequenceDiagram
participant Client as 客户端
participant Provider as LLMProvider
participant API as LLM API
Client->>Provider : Generate(req)
Provider->>API : 发送请求
API-->>Provider : 返回完整响应
Provider-->>Client : 返回CompletionResponse
Client->>Provider : Stream(req)
Provider->>API : 发送流式请求
loop 持续接收数据块
API->>Provider : 发送数据块
Provider->>Client : 转发数据块
end
API->>Provider : 关闭连接
Provider->>Client : 关闭流通道
```

**图源**
- [llm.go](file://internal/infrastructure/llm/llm.go#L38-L40)

### 配置路由规则
LLM提供商的路由规则在`Registry`结构体中管理，通过`GetLLMProvider`方法根据提供商名称获取相应的实例。系统支持默认提供商和按名称查找。

```mermaid
flowchart TD
GetProvider([GetLLMProvider]) --> Normalize["规范化提供商名称"]
Normalize --> CheckCache{"缓存中存在?"}
CheckCache --> |是| ReturnCached["返回缓存实例"]
CheckCache --> |否| CheckDefault{"默认提供商?"}
CheckDefault --> |是| ResolveSystem["解析系统默认提供商"]
CheckDefault --> |否| ResolveName["解析指定名称"]
ResolveSystem --> CheckCache2{"缓存中存在?"}
ResolveName --> CheckCache2
CheckCache2 --> |是| ReturnCached2["返回缓存实例"]
CheckCache2 --> |否| CreateNew["创建新提供商实例"]
CreateNew --> StoreCache["存储到缓存"]
StoreCache --> ReturnNew["返回新实例"]
ReturnCached --> End
ReturnCached2 --> End
ReturnNew --> End
End([完成])
```

**图源**
- [router.go](file://internal/infrastructure/llm/router.go#L37-L108)

### 处理认证与限流
系统通过配置文件管理不同LLM提供商的认证密钥，并在注册中心中根据提供商类型选择相应的API密钥。限流处理通常在提供商客户端实现中完成。

```mermaid
flowchart TD
LoadConfig([加载配置]) --> ReadEnv["读取环境变量"]
ReadEnv --> SetLLM["设置LLM配置"]
SetLLM --> ProviderType{"提供商类型"}
ProviderType --> OpenAI["openai"]
ProviderType --> DeepSeek["deepseek"]
ProviderType --> DashScope["dashscope"]
ProviderType --> Gemini["gemini"]
ProviderType --> Ollama["ollama"]
ProviderType --> SiliconFlow["siliconflow"]
OpenAI --> GetOpenAIKey["获取OPENAI_API_KEY"]
DeepSeek --> GetDeepSeekKey["获取DEEPSEEK_API_KEY"]
DashScope --> GetDashScopeKey["获取DASHSCOPE_API_KEY"]
Gemini --> GetGeminiKey["获取GEMINI_API_KEY"]
Ollama --> GetOllamaURL["获取LLM_BASE_URL"]
SiliconFlow --> GetSiliconFlowKey["获取SILICONFLOW_API_KEY"]
GetOpenAIKey --> CreateConfig
GetDeepSeekKey --> CreateConfig
GetDashScopeKey --> CreateConfig
GetGeminiKey --> CreateConfig
GetOllamaURL --> CreateConfig
GetSiliconFlowKey --> CreateConfig
CreateConfig --> ReturnConfig["返回配置实例"]
```

**图源**
- [config.go](file://internal/pkg/config/config.go#L8-L133)

## 前端功能模块扩展

前端采用模块化架构，支持通过添加新页面、状态管理store和i18n翻译来扩展功能。

### 新增页面
新页面可以通过在`features`目录下创建相应模块并添加路由来实现。系统使用React Router进行路由管理。

```mermaid
flowchart TD
AppStart([App组件]) --> RenderLayout["渲染布局"]
RenderLayout --> CreateSidebar["创建侧边栏导航"]
CreateSidebar --> DefineRoutes["定义路由"]
DefineRoutes --> RouteHome["根路径 -> HomePage"]
DefineRoutes --> RouteMeeting["/meeting -> MeetingRoom"]
DefineRoutes --> RouteEditor["/editor -> WorkflowEditor"]
DefineRoutes --> RouteGroups["/groups -> GroupsPage"]
DefineRoutes --> RouteAgents["/agents -> AgentsPage"]
DefineRoutes --> RouteWildcard["* -> HomePage"]
RouteHome --> LoadHomePage
RouteMeeting --> LoadMeetingRoom
RouteEditor --> LoadWorkflowEditor
RouteGroups --> LoadGroupsPage
RouteAgents --> LoadAgentsPage
RouteWildcard --> LoadHomePage
```

**图源**
- [App.tsx](file://frontend/src/App.tsx#L28-L84)

### 状态管理store
状态管理使用Zustand库实现，通过创建store来管理应用状态。每个功能模块可以有自己的store来管理特定状态。

```mermaid
classDiagram
class useWorkflowRunStore {
+nodes : Node<RuntimeNode>[]
+edges : Edge[]
+activeNodeIds : Set<string>
+executionStatus : 'idle' | 'running' | 'paused' | 'completed' | 'failed'
+humanReview : HumanReviewRequest | null
+graphDefinition : BackendGraph | null
+stats : {totalNodes, completedNodes, failedNodes, totalTokens, totalCostUsd, elapsedTimeMs}
+loadWorkflow(nodes, edges)
+setGraphFromTemplate(template)
+clearWorkflow()
+updateNodeStatus(nodeId, status, error)
+setActiveNodes(nodeIds)
+addActiveNode(nodeId)
+removeActiveNode(nodeId)
+updateNodeTokenUsage(nodeId, usage)
+setExecutionStatus(status)
+sendControl(sessionId, action)
+setHumanReview(request)
+submitHumanReview(req, action, data)
+startTimer()
+stopTimer()
}
class useConfigStore {
+theme : 'light' | 'dark' | 'system'
+language : 'en' | 'zh-CN'
+setTheme(theme)
+setLanguage(language)
}
class useAuthStore {
+user : User | null
+isLoggedIn : boolean
+login(credentials)
+logout()
+checkAuth()
}
class useSessionStore {
+sessions : Session[]
+currentSession : Session | null
+createSession(config)
+loadSession(id)
+saveSession(session)
+deleteSession(id)
}
class useWorkflowRunStore
class useConfigStore
class useAuthStore
class useSessionStore
```

**图源**
- [useWorkflowRunStore.ts](file://frontend/src/stores/useWorkflowRunStore.ts#L14-L301)

### i18n翻译
国际化支持通过i18next实现，支持多语言翻译。新的翻译内容可以通过添加语言文件来扩展。

```mermaid
flowchart TD
InitI18n([初始化i18n]) --> Configure["配置i18next"]
Configure --> SetResources["设置资源文件"]
SetResources --> en["英文资源"]
SetResources --> zhCN["中文资源"]
SetResources --> AddMore["添加更多语言"]
en --> LoadEnTranslation["加载en/translation.json"]
zhCN --> LoadZhCNTranslation["加载zh-CN/translation.json"]
Configure --> SetOptions["设置选项"]
SetOptions --> SetFallback["设置备用语言"]
SetOptions --> SetSupported["设置支持语言"]
SetOptions --> SetDetection["设置检测顺序"]
SetDetection --> localStorage["localStorage"]
SetDetection --> navigator["浏览器语言"]
SetDetection --> htmlTag["HTML标签"]
SetOptions --> SetCaches["设置缓存"]
SetCaches --> localStorageCache["localStorage"]
Configure --> InitLibrary["初始化库"]
InitLibrary --> UseDetector["使用LanguageDetector"]
InitLibrary --> UseReact["使用initReactI18next"]
InitLibrary --> Complete["完成初始化"]
```

**图源**
- [i18n/index.ts](file://frontend/src/i18n/index.ts#L1-L35)

## 扩展点设计原则

### 保持无状态
工作流节点处理器应保持无状态设计，所有状态信息通过输入参数和输出结果传递，避免在处理器实例中存储可变状态。

### 支持配置化
系统应支持通过配置文件和运行时参数进行配置，避免硬编码。LLM提供商、模型选择、API密钥等都应通过配置管理。

### 遵循现有架构模式
新功能的扩展应遵循现有的架构模式，如使用工厂模式创建处理器、通过注册中心管理提供商、采用模块化前端结构等，确保代码的一致性和可维护性。